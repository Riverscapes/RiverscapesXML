{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Creating EVT and BPS Symbology\n",
    "\n",
    "1. Load the CSV file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "import os\n",
    "bps_root = ET.parse('us_200bps.tif.aux.xml').getroot()\n",
    "evt_root = ET.parse('us_200evt.tif.aux.xml').getroot()\n",
    "os.makedirs('output', exist_ok=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def sort_and_write(filename, rows):\n",
    "  \"\"\"Here's a little helper function to write our .clr file once we have the format\n",
    "\n",
    "  Args:\n",
    "      filename ([type]): [description]\n",
    "      rows ([type]): This is going to be a list of lists in the form: [[VAL(float), R(int),G(int),B(int), Label(str)], ...]\n",
    "  \"\"\"\n",
    "  # Now sort by value column\n",
    "  rows_sorted = sorted(rows, key=lambda k : k[0])\n",
    "\n",
    "  # Open up a csvfile for writing as a TSV (Tab delimited)\n",
    "  with open(os.path.join('output', filename), 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter='\\t')\n",
    "    # Write the file\n",
    "    for r in rows_sorted:\n",
    "      writer.writerow(r)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2046266001.py, line 12)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/f5/j0ccyqcn0yndd30nd28scxp00000gp/T/ipykernel_97046/2046266001.py\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    with open(os.path.join('output', filename, 'w', newline='') as csvfile:\u001b[0m\n\u001b[0m                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Extract the field definitions and the values\n",
    "bps_defns_arr = bps_root.findall('PAMRasterBand/GDALRasterAttributeTable/FieldDefn')\n",
    "bps_defns = [{c.tag:c.text for c in r.findall('*') } for r in bps_defns_arr]\n",
    "\n",
    "bps_rows_arr = bps_root.findall('PAMRasterBand/GDALRasterAttributeTable/Row')\n",
    "bps_rows = [{bps_defns[i]['Name']:c.text for i,c in enumerate(r.findall('*')) } for r in bps_rows_arr]\n",
    "\n",
    "evt_defns_arr = evt_root.findall('PAMRasterBand/GDALRasterAttributeTable/FieldDefn')\n",
    "evt_defns = [{c.tag:c.text for c in r.findall('*') } for r in evt_defns_arr]\n",
    "\n",
    "evt_rows_arr = evt_root.findall('PAMRasterBand/GDALRasterAttributeTable/Row')\n",
    "evt_rows = [{evt_defns[i]['Name']:c.text for i,c in enumerate(r.findall('*')) } for r in evt_rows_arr]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Now make an array of rows for the symbologies we want\n",
    "def write_clr(value_col, label_col, ds):\n",
    "    rows = []\n",
    "    for r in ds:\n",
    "      r_val = r['r'] if 'r' in r else r['R']\n",
    "      g_val = r['g'] if 'g' in r else r['G']\n",
    "      b_val = r['b'] if 'b' in r else r['B']\n",
    "      rows.append([r[value_col], r_val, g_val, b_val, '{}: {}'.format(r[value_col], r[label_col])])\n",
    "    return rows\n",
    "\n",
    "evt_names = write_clr('VALUE', 'EVT_Name', evt_rows)\n",
    "bps_names = write_clr('VALUE', 'BPS_NAME', bps_rows)\n",
    "\n",
    "sort_and_write('evt_names.clr', evt_names)\n",
    "sort_and_write('bps_names.clr', bps_names)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Existing_Veg_EVT_Class \n",
    "\n",
    "This one needs a little extra care because it needs a custom palett"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load the color lookup from the JSON file\n",
    "import json\n",
    "\n",
    "def veg_class():\n",
    "  with open('evt_class_lookup.json', 'r') as f:\n",
    "    evt_class_lookup = json.load(f)\n",
    "\n",
    "  evt_classes = []\n",
    "  rows = []\n",
    "  for r in evt_rows:\n",
    "    if r['EVT_CLASS'] not in evt_classes:\n",
    "      evt_classes.append(r['EVT_CLASS'])\n",
    "    if r['EVT_CLASS'] not in evt_class_lookup:\n",
    "      raise Exception('Could not find class \"{}\" in lookup'.format(r['EVT_CLASS']))\n",
    "\n",
    "    rows.append([r['VALUE'], *evt_class_lookup[r['EVT_CLASS']], r['EVT_CLASS']])\n",
    "\n",
    "  # Here are the keys from the JSON\n",
    "  print(\"Lookup Values\", evt_class_lookup.keys(), len(evt_class_lookup.keys()))\n",
    "\n",
    "  # Here are the unique values we found in the RAT\n",
    "  print(\"RAT Values\", evt_classes, len(evt_classes))\n",
    "\n",
    "  return rows\n",
    "\n",
    "sort_and_write('evt_classes.clr', veg_class())\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Lookup Values dict_keys(['Sparse tree canopy', 'Closed tree canopy', 'Herbaceous - shrub-steppe', 'Open tree canopy', 'Herbaceous - grassland', 'Shrubland', 'Sparsely vegetated', 'Dwarf-shrubland', 'No Dominant Lifeform', 'Non-vegetated', 'Open Tree Canopy']) 11\n",
      "RAT Values ['Sparse tree canopy', 'Closed tree canopy', 'Herbaceous - shrub-steppe', 'Open tree canopy', 'Herbaceous - grassland', 'Shrubland', 'Sparsely vegetated', 'Dwarf-shrubland', 'No Dominant Lifeform', 'Non-vegetated', 'Open Tree Canopy'] 11\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Existing_Veg_Riparian EVT\n",
    "\n",
    "For this one we need to do a test to see if the column has the label 'Riparian' or not"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "riparian_row = [0,255,0, 'Riparian']\n",
    "non_rip_row = [255,255,255, 'Non-Riparian']\n",
    "\n",
    "def riparian_test(ds, val_col, test_col, test_val):\n",
    "  rows = []\n",
    "  for r in ds:\n",
    "    if r[test_col] == test_val:\n",
    "      rows.append([r[val_col], *riparian_row])\n",
    "    else:\n",
    "      rows.append([r[val_col], *non_rip_row])\n",
    "  return rows\n",
    "\n",
    "evt_riparian = riparian_test(evt_rows, 'VALUE', 'EVT_PHYS', 'Riparian')\n",
    "bps_riparian = riparian_test(bps_rows, 'VALUE', 'GROUPVEG', 'Riparian')\n",
    "\n",
    "sort_and_write('EVT_Riparian.clr', evt_riparian)\n",
    "sort_and_write('BPS_Riparian.clr', bps_riparian)\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "71f8471034ffbb15bd6cb2ccfe9b64c03f1d92f909a214534aef9561a7bde131"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}